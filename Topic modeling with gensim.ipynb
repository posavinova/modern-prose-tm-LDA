{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rA1GL4iye-HB",
   "metadata": {
    "id": "rA1GL4iye-HB"
   },
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4CWrI3Cp0-So",
   "metadata": {
    "id": "4CWrI3Cp0-So"
   },
   "outputs": [],
   "source": [
    "!pip install -U fastparquet pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad707788",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade spacy -q\n",
    "!python -m spacy download ru_core_news_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd98171",
   "metadata": {
    "id": "5qibVtuh7Byo"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis wordcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb5ec82",
   "metadata": {
    "id": "1eb5ec82"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from statistics import mean\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8498c863",
   "metadata": {
    "id": "8498c863"
   },
   "outputs": [],
   "source": [
    "# spaCy for lemmatization\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d71bf76",
   "metadata": {
    "id": "7d71bf76"
   },
   "outputs": [],
   "source": [
    "# Gensim\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765fa923",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "765fa923",
    "outputId": "61a5e8e3-cbe2-4066-924a-45f372950897"
   },
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK stop-words\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac556562",
   "metadata": {
    "id": "ac556562"
   },
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "\n",
    "df = pd.read_csv('november_prose_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0087c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c0087c4",
    "outputId": "0d24b27d-aeec-41f0-97e9-2fc6355b1675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                               text\n",
      "0   1046  \\nЩепинские рассказы, или Яшкины были. \\n \\n  ...\n",
      "1   1052  \\n     Речушка была и не широкой, и не глубоко...\n",
      "2   1061  \\nСолнечное весеннее утро. Сквозь нежно-зелены...\n",
      "3   1067  \\nМирабель уверенным шагом шла по мостовой. До...\n",
      "4   1072  \\n                 \\n     Первое сентября, пер...\n",
      "5   1078  \\n       Предыдущая глава здесь: \\n \\n       Т...\n",
      "6   1080  \\n     Бабушка. Слово-то какое доброе, теплое....\n",
      "7   1088  \\nЧудеса  происходят и сегодня. \\n \\n  \\n \\n М...\n",
      "8   1095  \\nГ л у п о  п р о д а в а т ь  в е щ и  в  г ...\n",
      "9   1099  \\nЭнергия направленного действия. \\nГл. из ром...\n",
      "10  1108  \\nАвтобус с омоновцами остановился на въезде в...\n",
      "11  1109  \\nВ преферанс я научился играть… нет, не раньш...\n",
      "\n",
      "- Total size of the corpus: 2376 short stories\n"
     ]
    }
   ],
   "source": [
    "print(df.head(12))\n",
    "print('\\n- Total size of the corpus:', len(df), 'short stories')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yVU_TtBsgBfG",
   "metadata": {
    "id": "yVU_TtBsgBfG"
   },
   "source": [
    "### **Text preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "D6vsmaEbAul3",
   "metadata": {
    "id": "D6vsmaEbAul3"
   },
   "outputs": [],
   "source": [
    "pattern_1 = re.compile(pattern='[^а-яё\\.?!\\s\\\\n-]|\\W+-\\W+', flags=re.IGNORECASE)\n",
    "pattern_2 = re.compile(pattern='!+|\\?+|\\.+')\n",
    "pattern_3 = re.compile(pattern='(?<=\\s)\\.(?=\\s\\w)')\n",
    "pattern_4 = re.compile(pattern=' {2,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "KTVFGjuhYDa3",
   "metadata": {
    "id": "KTVFGjuhYDa3"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].replace(to_replace=pattern_1, value=' ', regex=True)\n",
    "df['text'] = df['text'].replace(to_replace=pattern_2, value='.', regex=True)\n",
    "df['text'] = df['text'].replace(to_replace=pattern_3, value='', regex=True)\n",
    "df['text'] = df['text'].replace(to_replace=pattern_4, value=' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "h1SueVbc3oZL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1SueVbc3oZL",
    "outputId": "345db401-dedf-4c8d-dd08-fca3a5ce9e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Average size of short stories in words: 1760\n",
      "\n",
      "- Average size of short stories in characters: 11258\n"
     ]
    }
   ],
   "source": [
    "# Some text statistics for chunking\n",
    "df['text_word_len'] = df['text'].str.split().str.len()\n",
    "df['text_char_len'] = df['text'].str.len()\n",
    "\n",
    "avg_word_text = ceil(df['text_word_len'].mean())\n",
    "avg_char_text = ceil(df['text_char_len'].mean())\n",
    "\n",
    "print('\\n- Average size of short stories in words:', avg_word_text)\n",
    "print('\\n- Average size of short stories in characters:', avg_char_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "COr2GgY9aog-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COr2GgY9aog-",
    "outputId": "fcf1be1f-9497-4596-9a33-4747ded7c561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Average sentence length in words: 13\n",
      "\n",
      "- Average sentence length in characters: 79\n"
     ]
    }
   ],
   "source": [
    "# Some setence statistics for chunking\n",
    "\n",
    "def get_sent_stats_words(text):\n",
    "    words = ceil(mean([len(sent.split()) for sent in [story for story in text.split('.')]]))\n",
    "    return words\n",
    "\n",
    "def get_sent_stats_chars(text):\n",
    "    chars = ceil(mean([len(sent) for sent in text.split('.')]))\n",
    "    return chars\n",
    "\n",
    "df['sent_word_len'] = df['text'].apply(get_sent_stats_words)\n",
    "df['sent_char_len'] = df['text'].apply(get_sent_stats_chars)\n",
    "\n",
    "avg_word_sent = ceil(df['sent_word_len'].mean())\n",
    "avg_char_sent = ceil(df['sent_char_len'].mean())\n",
    "\n",
    "print('\\n- Average sentence length in words:', avg_word_sent)\n",
    "print('\\n- Average sentence length in characters:', avg_char_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aiO80Ua_CO-C",
   "metadata": {
    "id": "aiO80Ua_CO-C"
   },
   "outputs": [],
   "source": [
    "# Transforming to lower case\n",
    "\n",
    "df['text_lower']  = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7uYmxrWk-3ie",
   "metadata": {
    "id": "7uYmxrWk-3ie"
   },
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "\n",
    "def remove_stops(data):\n",
    "    no_stops = ' '.join([word for word in str(data).split() if word not in stop_words])\n",
    "    return no_stops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "oNOyR1Jq2bxI",
   "metadata": {
    "id": "oNOyR1Jq2bxI"
   },
   "outputs": [],
   "source": [
    "df['no_stops_text'] = df['text_lower'].apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "JMABp5VtxO2L",
   "metadata": {
    "id": "JMABp5VtxO2L"
   },
   "outputs": [],
   "source": [
    "# Initialize spacy 'ru' model, keeping only tagger component (for efficiency)\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm', disable=['parser', 'ner'])\n",
    "nlp.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GtPdheXkFIZh",
   "metadata": {
    "id": "GtPdheXkFIZh"
   },
   "outputs": [],
   "source": [
    "def lemmatize(data, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    lemmatized = []\n",
    "    for text in data:\n",
    "        doc = nlp(text) \n",
    "        lemmatized.append([token.lemma_ for token in tqdm(doc) if token.pos_ in allowed_postags])\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "KTYnrMailTYL",
   "metadata": {
    "id": "KTYnrMailTYL"
   },
   "outputs": [],
   "source": [
    "df['text_lemma'] = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c24a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing tokens with spaCy \n",
    "\n",
    "data_lemmatized = lemmatize(df['no_stops_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "423mNesbhEE3",
   "metadata": {
    "id": "423mNesbhEE3"
   },
   "outputs": [],
   "source": [
    "# Converting to list\n",
    "\n",
    "lemmatized = df['text_lemma'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "\n",
    "bigram = gensim.models.Phrases(lemmatized, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "# trigram = gensim.models.Phrases(bigram[lemmatized], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "# trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d91cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for bigrams, trigrams and lemmatization\n",
    "# Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# def make_trigrams(texts):\n",
    "#     return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df8728f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "\n",
    "data_bigrams = make_bigrams(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9793b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_bigrams'] = data_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "JKgRR4iyg6O9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "JKgRR4iyg6O9",
    "outputId": "ed828589-a56a-4a66-e500-8fde84e27193"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_word_len</th>\n",
       "      <th>text_char_len</th>\n",
       "      <th>sent_word_len</th>\n",
       "      <th>sent_char_len</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>no_stops_text</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>text_bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36. Прогулка с лётчиком. from1988, Из цикла Мо...</td>\n",
       "      <td>. ПРОГУЛКА С ЛЁТЧИКОМ. \\n Замерзшая Атлантика...</td>\n",
       "      <td>1663</td>\n",
       "      <td>11131</td>\n",
       "      <td>17</td>\n",
       "      <td>110</td>\n",
       "      <td>. прогулка с лётчиком. \\n замерзшая атлантика...</td>\n",
       "      <td>. прогулка лётчиком. замерзшая атлантика нарис...</td>\n",
       "      <td>[прогулка, лётчик, замёрзнуть, атлантика, нари...</td>\n",
       "      <td>[прогулка, лётчик, замёрзнуть, атлантика, нари...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Награды и награждаемые из книги академия жизни-1</td>\n",
       "      <td>\\nНАГРАДЫ И НАГРАЖДАЕМЫЕ \\n \\n \\nВообще наград...</td>\n",
       "      <td>1648</td>\n",
       "      <td>10525</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>\\nнаграды и награждаемые \\n \\n \\nвообще наград...</td>\n",
       "      <td>награды награждаемые вообще награды дело хорош...</td>\n",
       "      <td>[награда, награждать, вообще, награда, дело, х...</td>\n",
       "      <td>[награда, награждать, вообще, награда, дело, х...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Отрывок из книги Мукамал</td>\n",
       "      <td>\\nМ У К А М А Л -отрывок. \\n БЫЛЬ \\n .Эта подл...</td>\n",
       "      <td>1287</td>\n",
       "      <td>8106</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>\\nм у к а м а л -отрывок. \\n быль \\n .эта подл...</td>\n",
       "      <td>м м л -отрывок. быль .эта подлинная история де...</td>\n",
       "      <td>[м, м, л, быль, .эта, подлинный, история, деву...</td>\n",
       "      <td>[м, м, л, быль, .эта, подлинный, история, деву...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Князь Владимир 12</td>\n",
       "      <td>Т е б я с ю д а в л о в у ш к у з а м а н и л ...</td>\n",
       "      <td>370</td>\n",
       "      <td>1750</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>т е б я с ю д а в л о в у ш к у з а м а н и л ...</td>\n",
       "      <td>т е б ю д л ш з м н л киевский князь ярополк о...</td>\n",
       "      <td>[е, б, ю, д, л, киевский, князь, рогнеда, выхо...</td>\n",
       "      <td>[е, б_ю, д_л, киевский_князь, рогнеда, выходит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кулёма - забытое слово из далёкого детства</td>\n",
       "      <td>\\nЕсли быть предельно точным то правильно это ...</td>\n",
       "      <td>472</td>\n",
       "      <td>3286</td>\n",
       "      <td>17</td>\n",
       "      <td>117</td>\n",
       "      <td>\\nесли быть предельно точным то правильно это ...</td>\n",
       "      <td>предельно точным правильно это слово звучит ку...</td>\n",
       "      <td>[предельно, точный, правильно, слово, звучать,...</td>\n",
       "      <td>[предельно, точный, правильно, слово, звучать,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  36. Прогулка с лётчиком. from1988, Из цикла Мо...   \n",
       "1   Награды и награждаемые из книги академия жизни-1   \n",
       "2                           Отрывок из книги Мукамал   \n",
       "3                                  Князь Владимир 12   \n",
       "4         Кулёма - забытое слово из далёкого детства   \n",
       "\n",
       "                                                text  text_word_len  \\\n",
       "0   . ПРОГУЛКА С ЛЁТЧИКОМ. \\n Замерзшая Атлантика...           1663   \n",
       "1  \\nНАГРАДЫ И НАГРАЖДАЕМЫЕ \\n \\n \\nВообще наград...           1648   \n",
       "2  \\nМ У К А М А Л -отрывок. \\n БЫЛЬ \\n .Эта подл...           1287   \n",
       "3  Т е б я с ю д а в л о в у ш к у з а м а н и л ...            370   \n",
       "4  \\nЕсли быть предельно точным то правильно это ...            472   \n",
       "\n",
       "   text_char_len  sent_word_len  sent_char_len  \\\n",
       "0          11131             17            110   \n",
       "1          10525             11             67   \n",
       "2           8106             16            100   \n",
       "3           1750              7             32   \n",
       "4           3286             17            117   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0   . прогулка с лётчиком. \\n замерзшая атлантика...   \n",
       "1  \\nнаграды и награждаемые \\n \\n \\nвообще наград...   \n",
       "2  \\nм у к а м а л -отрывок. \\n быль \\n .эта подл...   \n",
       "3  т е б я с ю д а в л о в у ш к у з а м а н и л ...   \n",
       "4  \\nесли быть предельно точным то правильно это ...   \n",
       "\n",
       "                                       no_stops_text  \\\n",
       "0  . прогулка лётчиком. замерзшая атлантика нарис...   \n",
       "1  награды награждаемые вообще награды дело хорош...   \n",
       "2  м м л -отрывок. быль .эта подлинная история де...   \n",
       "3  т е б ю д л ш з м н л киевский князь ярополк о...   \n",
       "4  предельно точным правильно это слово звучит ку...   \n",
       "\n",
       "                                          text_lemma  \\\n",
       "0  [прогулка, лётчик, замёрзнуть, атлантика, нари...   \n",
       "1  [награда, награждать, вообще, награда, дело, х...   \n",
       "2  [м, м, л, быль, .эта, подлинный, история, деву...   \n",
       "3  [е, б, ю, д, л, киевский, князь, рогнеда, выхо...   \n",
       "4  [предельно, точный, правильно, слово, звучать,...   \n",
       "\n",
       "                                        text_bigrams  \n",
       "0  [прогулка, лётчик, замёрзнуть, атлантика, нари...  \n",
       "1  [награда, награждать, вообще, награда, дело, х...  \n",
       "2  [м, м, л, быль, .эта, подлинный, история, деву...  \n",
       "3  [е, б_ю, д_л, киевский_князь, рогнеда, выходит...  \n",
       "4  [предельно, точный, правильно, слово, звучать,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_parquet('proza_lem.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hE4Eqv_qfzCd",
   "metadata": {
    "id": "hE4Eqv_qfzCd"
   },
   "source": [
    "### **Latent Dirichlet Allocation (LDA)**\n",
    "##### *(topics as probability distributions for the occurrence of different words)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b9807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('proza_lem.parquet', engine='pyarrow', columns=['title', 'text_bigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3186ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = df1['text_bigrams'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ab90480",
   "metadata": {
    "id": "6ab90480"
   },
   "outputs": [],
   "source": [
    "# Creating Dictionary\n",
    "\n",
    "id2word = corpora.Dictionary(data_bigrams)\n",
    "\n",
    "# Creating Corpus\n",
    "\n",
    "texts = data_bigrams\n",
    "\n",
    "# Term Document Frequency\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c27c61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15c27c61",
    "outputId": "c84f1028-450c-412a-a3ac-677650f8ea69"
   },
   "outputs": [],
   "source": [
    "# View\n",
    "\n",
    "print(corpus[0])\n",
    "\n",
    "# Human readable term-frequency\n",
    "\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58e665c0",
   "metadata": {
    "id": "58e665c0"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=6):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b85abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running several models\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=2, limit=49, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "\n",
    "limit=49; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a272296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MH_65msizy6H",
   "metadata": {
    "id": "MH_65msizy6H"
   },
   "source": [
    "Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uwdEJUCi7dAQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwdEJUCi7dAQ",
    "outputId": "3a48018f-5c47-46d6-b850-38e382d3dd96"
   },
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "\n",
    "optimal_model = model_list[5]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u7Gyn71LZTkm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u7Gyn71LZTkm",
    "outputId": "fd5e7f14-ed90-4ee6-daa7-ece11be8fcfe"
   },
   "outputs": [],
   "source": [
    "# generating word clouds for each topic                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "\n",
    "for topic in range(optimal_model.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud().fit_words(dict(optimal_model.show_topic(topic, 20))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(topic))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1be6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916
    },
    "id": "fbd1be6c",
    "outputId": "67b83873-5c92-4c2c-d76b-caa9b9af405c"
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, corpus, id2word, mds='mmds') \n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hE4Eqv_qfzCd"
   ],
   "name": "TM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
